{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to load the europarl data into a list of sentences\n",
    "def load_sentences(file):\n",
    "    doc = open(file, mode='rt', encoding='utf-8')\n",
    "    text = doc.read()\n",
    "    doc.close()\n",
    "    return text.strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_english = 'es-en/europarl-v7.es-en.en'\n",
    "file_spanish = 'es-en/europarl-v7.es-en.es'\n",
    "english = load_sentences(file_english)\n",
    "spanish = load_sentences(file_spanish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For simplicity, remove all punctuation and lowercase all text. \n",
    "# Argument: List of sentences (as strings)\n",
    "# Returns: List of lists of tokens\n",
    "def clean(sentences):\n",
    "    cleaned = []\n",
    "    for sentence in sentences:\n",
    "        # This is cleaner than splitting on whitespace since it allows us to\n",
    "        # keep hyphens while removing punctuation, separate possessive apostrophes, etc\n",
    "        clean = word_tokenize(sentence)\n",
    "        # words consisting of not /only/ punctuation, and no numbers\n",
    "        clean = [word.lower() for word in clean if word not in punctuation and not word.isnumeric()]\n",
    "        cleaned.append(clean)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "en_clean = clean(english)\n",
    "es_clean = clean(spanish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Return a dictionary with counts of the number of times a token occurred in the corpora.\n",
    "def get_tokens(clean_data):\n",
    "    tokens = {}\n",
    "    for sentence in clean_data:\n",
    "        for token in sentence:\n",
    "            if token in tokens:\n",
    "                tokens[token] += 1\n",
    "            else:\n",
    "                tokens[token] = 1\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a much, much smaller version of the data so we can test quickly!\n",
    "en_mini = ['that book is red', 'a yellow car', 'was that a red book', \n",
    "           'the car was red', 'yellow book', 'a car', 'that is a book', \n",
    "           'the yellow car', 'the book']\n",
    "\n",
    "es_mini = ['eso libro es rojo', 'un carro amarillo', 'era eso un libro rojo',\n",
    "           'el carro era rojo', 'libro amarillo', 'un carro', \n",
    "           'eso es un libro', 'el carro amarillo', 'el libro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "en_mini_clean = [lst.split() for lst in en_mini]\n",
    "es_mini_clean = [lst.split() for lst in es_mini]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Takes two lists of lists of words and a threshhold percentage of sentences that words must either\n",
    "# both appear in or both not appear in, and returns a dictionary of words that occur in similar places.\n",
    "def is_word_present_model(source_data, target_data, threshold):\n",
    "    source_tokens = get_tokens(source_data)\n",
    "    target_tokens = get_tokens(target_data)\n",
    "    \n",
    "    # should be the same for source and target (could assert this)\n",
    "    num_sentences = len(source_data)\n",
    "    \n",
    "    # these will have arrays of 1s and 0s corresponding to whether or not a word appeared in sentence i\n",
    "    s_present = dict((token, []) for token in source_tokens.keys())\n",
    "    t_present = dict((token, []) for token in target_tokens.keys())\n",
    "    \n",
    "    for token in source_tokens.keys():\n",
    "        for sentence in source_data:\n",
    "            if token in sentence:\n",
    "                s_present[token].append(1)\n",
    "            else:\n",
    "                s_present[token].append(0)\n",
    "                \n",
    "    for token in target_tokens.keys():\n",
    "        for sentence in target_data:\n",
    "            if token in sentence:\n",
    "                t_present[token].append(1)\n",
    "            else:\n",
    "                t_present[token].append(0)\n",
    "                \n",
    "    source_to_target = dict((token, []) for token in source_tokens.keys())\n",
    "    \n",
    "    for s_token in s_present.keys():\n",
    "        for t_token in t_present.keys():\n",
    "            match_percent = sum([i == j for i, j in zip(s_present[s_token], t_present[t_token])]) / num_sentences\n",
    "            if match_percent > threshold:\n",
    "                source_to_target[s_token].append(t_token)\n",
    "    \n",
    "    return source_to_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': ['un'],\n",
       " 'book': ['libro'],\n",
       " 'car': ['carro'],\n",
       " 'is': ['es'],\n",
       " 'red': ['rojo'],\n",
       " 'that': ['eso'],\n",
       " 'the': ['el'],\n",
       " 'was': ['era'],\n",
       " 'yellow': ['amarillo']}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this works very well on our contrived, one-to-one correspondant data\n",
    "is_word_present_model(en_mini_clean, es_mini_clean, .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the above function will take a very long time to run on our dataset. \n",
    "# we can use this to reduce the number of words, since words that only occur a few times\n",
    "# are likely less important--filter out proper names\n",
    "def reduce_vocab(data, min_occurrence):\n",
    "    tokens = get_tokens(data)\n",
    "    vocab = []\n",
    "    for token in tokens.keys():\n",
    "        if tokens[token] >= min_occurrence:\n",
    "            vocab.append(token)\n",
    "    \n",
    "    new_data = []\n",
    "    for sentence in data:\n",
    "        new_data.append([token for token in sentence if token in vocab])\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced_en_2000 = reduce_vocab(en_clean[:2000], 12)\n",
    "reduced_es_2000 = reduce_vocab(es_clean[:2000], 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_2000 = is_word_present_model(reduced_en_2000, reduced_es_2000, .99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reduced_en_10000 = reduce_vocab(en_clean[:10000], 100)\n",
    "reduced_es_10000 = reduce_vocab(es_clean[:10000], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_10000_take_2 = is_word_present_model(reduced_en_10000, reduced_es_10000, .985)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# split the above function into two functions because varying the parameters on only the final loop\n",
    "# shouldn't require recomputing the boolean vectors\n",
    "def data_to_present_dicts(source_data, target_data):\n",
    "    source_tokens = get_tokens(source_data)\n",
    "    target_tokens = get_tokens(target_data)\n",
    "    \n",
    "    # these will have arrays of 1s and 0s corresponding to whether or not a word appeared in sentence i\n",
    "    s_present = dict((token, []) for token in source_tokens.keys())\n",
    "    t_present = dict((token, []) for token in target_tokens.keys())\n",
    "    \n",
    "    for token in source_tokens.keys():\n",
    "        for sentence in source_data:\n",
    "            if token in sentence:\n",
    "                s_present[token].append(1)\n",
    "            else:\n",
    "                s_present[token].append(0)\n",
    "                \n",
    "    for token in target_tokens.keys():\n",
    "        for sentence in target_data:\n",
    "            if token in sentence:\n",
    "                t_present[token].append(1)\n",
    "            else:\n",
    "                t_present[token].append(0)\n",
    "    return (s_present, t_present)\n",
    "\n",
    "# vary the number of sentences that need to match to align words\n",
    "def match_threshold(s_present, t_present, threshold, num_sentences):\n",
    "    source_to_target = dict((token, []) for token in s_present.keys())\n",
    "    s_appearances = dict((token, np.mean(s_present[token])) for token in s_present.keys())\n",
    "    t_appearances = dict((token, np.mean(t_present[token])) for token in t_present.keys())  \n",
    "    \n",
    "    num_acceptable_misses = math.ceil((1 - threshold) * num_sentences)\n",
    "    \n",
    "    for s_token in s_present.keys():\n",
    "        for t_token in t_present.keys():\n",
    "            # only compare words that occur at a similar frequency to one another\n",
    "            if abs(s_appearances[s_token] - t_appearances[t_token]) < 1 - threshold:\n",
    "                num_misses = 0\n",
    "                index = 0\n",
    "                while num_misses <= num_acceptable_misses:\n",
    "                    num_misses += (s_present[s_token][index] != t_present[t_token][index])\n",
    "                    if index == num_sentences - 1:\n",
    "                        source_to_target[s_token].append(t_token)\n",
    "                        break\n",
    "                    index += 1\n",
    "    \n",
    "    return source_to_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(en_present_10000, es_present_10000) = data_to_present_dicts(reduced_en_10000, reduced_es_10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_attempt = match_threshold(en_present_10000, es_present_10000, .981, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "en_reduced_25000 = reduce_vocab(en_clean[:25000], 200)\n",
    "es_reduced_25000 = reduce_vocab(es_clean[:25000], 200)\n",
    "(en_present_25000, es_present_25000) = data_to_present_dicts(en_reduced_25000, es_reduced_25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "large_attempt = match_threshold(en_present_25000, es_present_25000, .986, 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "en_reduced_100000 = reduce_vocab(en_clean[:100000], 500)\n",
    "es_reduced_100000 = reduce_vocab(es_clean[:100000], 500)\n",
    "(en_present_100000, es_present_100000) = data_to_present_dicts(en_reduced_100000, es_reduced_100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "larger_attempt = match_threshold(en_present_100000, es_present_100000, .99, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "larger_attempt2 = match_threshold(en_present_100000, es_present_100000, .992, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "es_to_en = match_threshold(es_present_100000, en_present_100000, .992, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'access': ['acceso'],\n",
       " 'actions': ['acciones'],\n",
       " 'activities': ['actividades'],\n",
       " 'agreements': ['acuerdos'],\n",
       " 'always': ['siempre'],\n",
       " 'amendment': ['enmienda'],\n",
       " 'amendments': ['enmiendas'],\n",
       " 'article': ['artículo'],\n",
       " 'aspects': ['aspectos'],\n",
       " 'attention': ['atención'],\n",
       " 'authorities': ['autoridades'],\n",
       " 'behalf': ['nombre'],\n",
       " 'budget': ['presupuesto'],\n",
       " 'cases': ['casos'],\n",
       " 'charter': ['carta'],\n",
       " 'children': ['niños'],\n",
       " 'citizens': ['ciudadanos'],\n",
       " 'communication': ['comunicación'],\n",
       " 'competition': ['competencia'],\n",
       " 'concern': ['preocupación'],\n",
       " 'conditions': ['condiciones'],\n",
       " 'conference': ['conferencia'],\n",
       " 'context': ['contexto'],\n",
       " 'control': ['control'],\n",
       " 'cooperation': ['cooperación'],\n",
       " 'costs': ['costes'],\n",
       " 'council': ['consejo'],\n",
       " 'court': ['tribunal'],\n",
       " 'create': ['crear'],\n",
       " 'currently': ['actualmente'],\n",
       " 'decision': ['decisión'],\n",
       " 'decisions': ['decisiones'],\n",
       " 'democracy': ['democracia'],\n",
       " 'dialogue': ['diálogo'],\n",
       " 'difficult': ['difícil'],\n",
       " 'directive': ['directiva'],\n",
       " 'draft': ['proyecto'],\n",
       " 'economy': ['economía'],\n",
       " 'efforts': ['esfuerzos'],\n",
       " 'employment': ['empleo'],\n",
       " 'energy': ['energía'],\n",
       " 'enlargement': ['ampliación'],\n",
       " 'environment': ['ambiente'],\n",
       " 'eur': ['millones', 'euros'],\n",
       " 'euro': ['euro'],\n",
       " 'example': ['ejemplo'],\n",
       " 'external': ['exterior'],\n",
       " 'farmers': ['jóvenes'],\n",
       " 'fight': ['lucha'],\n",
       " 'fisheries': ['pesca'],\n",
       " 'foreign': ['exterior'],\n",
       " 'free': ['libre'],\n",
       " 'freedom': ['libertad'],\n",
       " 'fundamental': ['fundamentales'],\n",
       " 'funds': ['fondos'],\n",
       " 'future': ['futuro'],\n",
       " 'government': ['gobierno'],\n",
       " 'governments': ['gobiernos'],\n",
       " 'group': ['grupo'],\n",
       " 'groups': ['grupos'],\n",
       " 'growth': ['crecimiento'],\n",
       " 'health': ['salud'],\n",
       " 'high': ['alto'],\n",
       " 'human': ['humanos'],\n",
       " 'idea': ['idea'],\n",
       " 'improve': ['mejorar'],\n",
       " 'industry': ['industria'],\n",
       " 'information': ['información'],\n",
       " 'initiative': ['iniciativa'],\n",
       " 'institutions': ['instituciones'],\n",
       " 'interest': ['interés'],\n",
       " 'interests': ['intereses'],\n",
       " 'internal': ['interior'],\n",
       " 'international': ['internacional'],\n",
       " 'justice': ['justicia'],\n",
       " 'kosovo': ['kosovo'],\n",
       " 'legislation': ['legislación'],\n",
       " 'life': ['vida'],\n",
       " 'madam': ['presidenta'],\n",
       " 'majority': ['mayoría'],\n",
       " 'management': ['gestión'],\n",
       " 'market': ['mercado'],\n",
       " 'measures': ['medidas'],\n",
       " 'million': ['millones', 'euros'],\n",
       " 'money': ['dinero'],\n",
       " 'months': ['meses'],\n",
       " 'mrs': ['sra'],\n",
       " 'negotiations': ['negociaciones'],\n",
       " 'nothing': ['nada'],\n",
       " 'objectives': ['objetivos'],\n",
       " 'opportunity': ['oportunidad'],\n",
       " 'organisations': ['organizaciones'],\n",
       " 'party': ['partido'],\n",
       " 'peace': ['paz'],\n",
       " 'period': ['período'],\n",
       " 'plan': ['plan'],\n",
       " 'points': ['puntos'],\n",
       " 'policies': ['políticas'],\n",
       " 'position': ['posición'],\n",
       " 'presidency': ['presidencia'],\n",
       " 'prevent': ['evitar'],\n",
       " 'principle': ['principio'],\n",
       " 'principles': ['principios'],\n",
       " 'problem': ['problema'],\n",
       " 'problems': ['problemas'],\n",
       " 'procedure': ['procedimiento'],\n",
       " 'procedures': ['procedimientos'],\n",
       " 'process': ['proceso'],\n",
       " 'products': ['productos'],\n",
       " 'programme': ['programa'],\n",
       " 'programmes': ['programas'],\n",
       " 'projects': ['proyectos'],\n",
       " 'proposals': ['propuestas'],\n",
       " 'protection': ['protección'],\n",
       " 'quality': ['calidad'],\n",
       " 'questions': ['preguntas'],\n",
       " 'rapporteur': ['ponente'],\n",
       " 'recent': ['últimos'],\n",
       " 'reform': ['reforma'],\n",
       " 'region': ['región'],\n",
       " 'regions': ['regiones'],\n",
       " 'regulation': ['reglamento'],\n",
       " 'relations': ['relaciones'],\n",
       " 'report': ['informe'],\n",
       " 'reports': ['informes'],\n",
       " 'research': ['investigación'],\n",
       " 'resolution': ['resolución'],\n",
       " 'resources': ['recursos'],\n",
       " 'responsibility': ['responsabilidad'],\n",
       " 'results': ['resultados'],\n",
       " 'rights': ['derechos'],\n",
       " 'risk': ['riesgo'],\n",
       " 'role': ['papel'],\n",
       " 'second': ['segunda'],\n",
       " 'secondly': ['segundo'],\n",
       " 'sector': ['sector'],\n",
       " 'service': ['servicio'],\n",
       " 'services': ['servicios'],\n",
       " 'single': ['único'],\n",
       " 'society': ['sociedad'],\n",
       " 'solution': ['solución'],\n",
       " 'statement': ['declaración'],\n",
       " 'step': ['paso'],\n",
       " 'strategy': ['estrategia'],\n",
       " 'summit': ['cumbre'],\n",
       " 'system': ['sistema'],\n",
       " 'systems': ['sistemas'],\n",
       " 'text': ['texto'],\n",
       " 'three': ['tres'],\n",
       " 'tomorrow': ['mañana', 'horas'],\n",
       " 'trade': ['comercio'],\n",
       " 'training': ['formación'],\n",
       " 'transport': ['transporte'],\n",
       " 'treaty': ['tratado'],\n",
       " 'turkey': ['turquía'],\n",
       " 'two': ['dos'],\n",
       " 'united': ['unidos'],\n",
       " 'women': ['mujeres'],\n",
       " 'words': ['palabras'],\n",
       " 'workers': ['trabajadores'],\n",
       " 'year': ['año'],\n",
       " 'years': ['años'],\n",
       " 'young': ['jóvenes']}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict((k,v) for k, v in larger_attempt2.items() if v != [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add common words to our dictionary in addition to ones that are machine learned\n",
    "en_to_es = larger_attempt2\n",
    "en_to_es['a'] = ['un', 'una']\n",
    "en_to_es['an'] = ['un', 'una']\n",
    "en_to_es['and'] = ['y']\n",
    "en_to_es['be'] = ['ser', 'estar']\n",
    "en_to_es['because'] = ['porque']\n",
    "en_to_es['between'] = ['entre']\n",
    "en_to_es['but'] = ['pero']\n",
    "en_to_es['can'] = ['puede']\n",
    "en_to_es['day'] = ['dia']\n",
    "en_to_es['days'] = ['dias']\n",
    "en_to_es['do'] = ['hacer']\n",
    "en_to_es['done'] = ['hecho']\n",
    "en_to_es['each'] = ['cada']\n",
    "en_to_es['from'] = ['de']\n",
    "en_to_es['go'] = ['ir']\n",
    "en_to_es['he'] = ['el']\n",
    "en_to_es['if'] = ['si']\n",
    "en_to_es['is'] = ['es']\n",
    "en_to_es['more'] = ['mas']\n",
    "en_to_es['no'] = ['no']\n",
    "en_to_es['not'] = ['no']\n",
    "en_to_es['of'] = ['de']\n",
    "en_to_es['our'] = ['nuestro']\n",
    "en_to_es['she'] = ['ella']\n",
    "en_to_es['the'] = ['el', 'la']\n",
    "en_to_es['today'] = ['hoy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The use of different samples and threshholds gave us different results, so add them to our dict\n",
    "for k, v in dict_attempt.items():\n",
    "    if len(v) == 1:\n",
    "        en_to_es[k] = v\n",
    "\n",
    "for k,v in large_attempt.items():\n",
    "    if len(v) == 1:\n",
    "        en_to_es[k] = v\n",
    "        \n",
    "for k,v in larger_attempt.items():\n",
    "    if len(v) == 1:\n",
    "        en_to_es[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "en_to_es = (dict((k,v) for k, v in en_to_es.items() if v != []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mostly only useful as a single-word dictionary, but sentences where word order is preserved are translatable\n",
    "def translate(en):\n",
    "    # Keep numbers the same\n",
    "    if en.isnumeric():\n",
    "        return en\n",
    "    \n",
    "    # If it is a single word, return the list of possible translations\n",
    "    if len(en.split()) == 1:\n",
    "        if en in en_to_es.keys():\n",
    "            return en_to_es[en]\n",
    "        else:\n",
    "            return 'Input not in dictionary'\n",
    "    \n",
    "    else:\n",
    "        result = ''\n",
    "        for word in en.split():\n",
    "            if word in en_to_es.keys():\n",
    "                result += en_to_es[word][0] + ' '\n",
    "            # keep numbers the same\n",
    "            elif word.isnumeric():\n",
    "                result += word + ' '\n",
    "        \n",
    "        if result == '':\n",
    "            return 'Input not in dictionary.'\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'el contexto de nuestro decisión '"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A cherry-picked example--the translator ignores \"big\" because it doesn't know it\n",
    "translate('the context of our big decision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queremos un reglamento '"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"we want a regulation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['un', 'una']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('an')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
